{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of files\n",
    "\n",
    "train_path = '/content/ICLR/train/train/' #path of directory where all images are placed\n",
    "train_list = glob.glob(train_path+\"*\")  #list of file names\n",
    "train_images_list = glob.glob(train_path+\"*/*\")\n",
    "train_ds = tf.data.Dataset.list_files(train_images_list)\n",
    "\n",
    "# for csv \n",
    "#train_ds = tf.data.Dataset.from_tensor_slices((filenames, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data augmentation function\n",
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "\n",
    "#transformation over the imaging\n",
    "\n",
    "def decode_img(img):\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32) \n",
    "  img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) \n",
    "  img = tf.image.random_flip_left_right(img)\n",
    "  img = tf.image.random_flip_up_down(img)\n",
    "  img = tf.image.random_brightness(img, 0.3)\n",
    "  return img\n",
    "\n",
    "def get_label(path):\n",
    "  part_list = tf.strings.split(path, \"/\")\n",
    "  # in the case where each class of images is in one folder\n",
    "  return part_list[-2] == class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "\n",
    "  img = tf.io.read_file(file_path)  #path of directory to read batch of images\n",
    "  img = decode_img(img)             #transformation\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf.data.Dataset.cache isnâ€™t really recommend when we have a really huge dataset, \n",
    "# since it loads the dataset once into memory for the entire duration of model training.\n",
    "\n",
    "num_threads = 5 \n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=num_threads)\n",
    "\n",
    "\n",
    "#train_ds = train_ds.cache()  #\n",
    "train_ds = train_ds.shuffle(10000)\n",
    "train_ds = train_ds.repeat(num_epochs) #number of epochs\n",
    "train_ds = train_ds.batch(128)        #batch size\n",
    "train_ds = train_ds.prefetch(1)       #prefetch to make disk reading fasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=num_epochs, steps_per_epoch=steps_per_epc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
